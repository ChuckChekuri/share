{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Code below for getting scores when using cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "start_time = time.time()\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "elapsed = time.time() - start_time\n",
    "print('Cross Validation Score Time %s' % time.strftime(\"%Hh:%Mm:%Ss\", time.gmtime(elapsed)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pretty Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay(cfm, display_labels=lep_dict.keys())\n",
    "fig = plt.figure(figsize=[8,8], edgecolor='#882233', facecolor='#AA99DD', dpi=70) \n",
    "disp.figure_ = fig\n",
    "ax = fig.add_axes()\n",
    "disp.plot(include_values=True, cmap='Blues', xticks_rotation='vertical', values_format=None, ax=fig.axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to print results of a Classification Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "def printSummary(clf, X, y, FeatureList):\n",
    "    # get soft probability predictions\n",
    "    pred_probabilities = clf.predict_proba(X)\n",
    "    #Choose class with the max probability as the prediction\n",
    "    y_hat = np.asarray([np.argmax(line) for line in pred_probabilities])\n",
    "\n",
    "    print('Score: %0.5f' % clf.score(y, y_hat))\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy_score(y_test, y_hat) * 100.0))\n",
    "    print('Precision Score: %0.5f' % precision_score(y, y_hat, average='macro'))\n",
    "    cfm = metrics.confusion_matrix(y, y_hat)\n",
    "    print(cfm)\n",
    "    sorted_idx = clf.feature_importances_.argsort()\n",
    "    plt.barh(FeatureList[sorted_idx][-15:], clf.feature_importances_[sorted_idx][-15:])\n",
    "    plt.xlabel(\"Xgboost Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to write an Boosted tree to from XGBoost classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree(xgb_model, filename, rankdir='UT'):\n",
    "    \"\"\"\n",
    "    Plot the tree in high resolution\n",
    "    :param xgb_model: xgboost trained model\n",
    "    :param filename: the pdf file where this is saved\n",
    "    :param rankdir: direction of the tree: default Top-Down (UT), accepts:'LR' for left-to-right tree\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import xgboost as xgb\n",
    "    import os\n",
    "    gvz = xgb.to_graphviz(xgb_model, num_trees=xgb_model.best_iteration, rankdir=rankdir)\n",
    "    _, file_extension = os.path.splitext(filename)\n",
    "    format = file_extension.strip('.').lower()\n",
    "    data = gvz.pipe(format=format)\n",
    "    full_filename = filename\n",
    "    with open(full_filename, 'wb') as f:\n",
    "        f.write(data)\n",
    "        \n",
    "plot_tree(clf, 'xgb_trees.pdf', rankdir='UT')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for grid searching \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "search_params = {\n",
    " 'max_depth':range(2,20,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "gsearch = GridSearchCV( estimator = xgb4, \n",
    "                        param_grid = search_params, \n",
    "                        scoring=scoring,\n",
    "                        n_jobs=4, \n",
    "                        cv=5,\n",
    "                        refit='accuracy',\n",
    "                       verbose=2)\n",
    "start_time = time.time()\n",
    "gsearch.fit(dtrain[featureList],dtrain[target], verbose=False)\n",
    "elapsed = time.time() - start_time\n",
    "print('Grid Search Time %s' % time.strftime(\"%Hh:%Mm:%Ss\", time.gmtime(elapsed)))\n",
    "\n",
    "i = gsearch.best_index_\n",
    "best_precision = gsearch.cv_results_['mean_test_precision_macro'][i]\n",
    "best_recall = gsearch.cv_results_['mean_test_recall_macro'][i]\n",
    "print('Best score (accuracy): {}'.format(gsearch.best_score_))\n",
    "print(\"Best Precision : %0.4f\" % best_precision)\n",
    "print(\"Best Recall    : %0.4f\" % best_recall)\n",
    "print('Number of Trees %d' % len(gsearch.best_estimator_.get_booster().get_dump()))\n",
    "gsearch.best_estimator_.get_xgb_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
